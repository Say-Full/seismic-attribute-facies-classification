{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 10 Commonly Used Attributes\n",
    "\n",
    "1. Second Derivative = Continuity, facies\n",
    "\n",
    "2. Reflection Intensity = Impedance contrasts, facies\n",
    "\n",
    "3. Envelope = Water saturation, facies changes, fault, changes in lithofacies and bed thickness, hydrocarbon\n",
    "\n",
    "4. Instantaneous Frequency = Hydrocarbon reservoir, fracture, interface, change in facies\n",
    "\n",
    "5. Instantaneous Phase = Fault and pinch-out, hydrocarbon reservoir trap, facies changes, continuities, terminations, interfaces\n",
    "\n",
    "6. Sweetness = Water saturation, indicator of clean and or relatively thicker ‘thin’ sands like deltaic deposits or channel sands, potential hydrocarbon reservoir (similar to horizon slices)\n",
    "\n",
    "7. Instantaneous Bandwidth = Facies\n",
    "\n",
    "8. Cosine Instantaneous Phase = Structural delineation, facies\n",
    "\n",
    "9. Dominant Frequency = Facies \n",
    "\n",
    "10. Semblance (untuk menghitung Coherence) = Discontinuity = kebalikan Variance (low coherence = high variance) = Stratigraphic discontinuities (fault, fractures, and channels), salt domes detection, reveal faults and fracture zones, stratigraphic features such as channels, deltaic deposits, turbidites, and slope and basin floor fans, facies changes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### .segy --> segyio --> Matplotlib --> .png"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import segyio\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "segy_dir = 'SEGY'\n",
    "assert os.path.exists(segy_dir), 'Dataset tidak ditemukan!'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "amp_in_dir = os.path.join(segy_dir, 'TrainingData_Image.segy')\n",
    "sd_in_dir = os.path.join(segy_dir, 'second-derivative.segy')\n",
    "ri_in_dir = os.path.join(segy_dir, 'reflection-intensity.segy')\n",
    "e_in_dir = os.path.join(segy_dir, 'envelope.segy')\n",
    "ifreq_in_dir = os.path.join(segy_dir, 'instantaneous-frequency.segy')\n",
    "ip_in_dir = os.path.join(segy_dir, 'instantaneous-phase.segy')\n",
    "s_in_dir = os.path.join(segy_dir, 'sweetness.segy')\n",
    "ib_in_dir = os.path.join(segy_dir, 'instantaneous-bandwith.segy')\n",
    "cip_in_dir = os.path.join(segy_dir, 'cosine-phase.segy')\n",
    "dfreq_in_dir = os.path.join(segy_dir, 'dominant-frequency.segy')\n",
    "sem_in_dir = os.path.join(segy_dir, 'variance-edge-method.segy')\n",
    "\n",
    "for dir in [amp_in_dir, sd_in_dir, ri_in_dir, e_in_dir, ifreq_in_dir, ip_in_dir, s_in_dir, ib_in_dir, cip_in_dir, dfreq_in_dir, sem_in_dir]:\n",
    "    assert os.path.isfile(dir), \"Dataset {} tidak ditemukan!\".format(dir.split(os.sep)[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_dir = os.path.join('output', 'Images')\n",
    "if not os.path.exists(out_dir):\n",
    "    os.makedirs(out_dir)\n",
    "\n",
    "amp_out_dir = os.path.join(out_dir, 'Amplitude')\n",
    "sd_out_dir = os.path.join(out_dir, 'Second Derivative')\n",
    "ri_out_dir = os.path.join(out_dir, 'Reflection Intensity')\n",
    "e_out_dir = os.path.join(out_dir, 'Envelope')\n",
    "ifreq_out_dir = os.path.join(out_dir, 'Instantaneous Frequency')\n",
    "ip_out_dir = os.path.join(out_dir, 'Instantaneous Phase')\n",
    "s_out_dir = os.path.join(out_dir, 'Sweetness')\n",
    "ib_out_dir = os.path.join(out_dir, 'Instantaneous Bandwith')\n",
    "cip_out_dir = os.path.join(out_dir, 'Cosine Instantaneous Phase')\n",
    "dfreq_out_dir = os.path.join(out_dir, 'Dominant Frequency')\n",
    "sem_out_dir = os.path.join(out_dir, 'Semblance')\n",
    "\n",
    "for dir in [amp_out_dir, sd_out_dir, ri_out_dir, e_out_dir, ifreq_out_dir, ip_out_dir, s_out_dir, ib_out_dir, cip_out_dir, dfreq_out_dir, sem_out_dir]:\n",
    "    if not os.path.exists(dir):\n",
    "        os.mkdir(dir)\n",
    "        os.mkdir(os.path.join(dir, 'Inlines'))\n",
    "        os.mkdir(os.path.join(dir, 'Crosslines'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jumlah Inlines: 590\n",
      "Jumlah Crosslines: 782\n"
     ]
    }
   ],
   "source": [
    "data_dir_dict = {\n",
    "    'amp': [amp_in_dir, amp_out_dir],\n",
    "    'sd': [sd_in_dir, sd_out_dir],\n",
    "    'ri': [ri_in_dir, ri_out_dir],\n",
    "    'e': [e_in_dir, e_out_dir],\n",
    "    'ifreq': [ifreq_in_dir, ifreq_out_dir],\n",
    "    'ip': [ip_in_dir, ip_out_dir],\n",
    "    's': [s_in_dir, s_out_dir],\n",
    "    'ib': [ib_in_dir, ib_out_dir],\n",
    "    'cip': [cip_in_dir, cip_out_dir],\n",
    "    'dfreq': [dfreq_in_dir, dfreq_out_dir],\n",
    "    'sem': [sem_in_dir, sem_out_dir]\n",
    "}\n",
    "\n",
    "n_inlines, n_crosslines = (590, 782)\n",
    "print(f'Jumlah Inlines: {n_inlines}')\n",
    "print(f'Jumlah Crosslines: {n_crosslines}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for k, v in data_dir_dict.items():\n",
    "#     # k = attributes name => unused\n",
    "#     # v[0] = data_in_dir\n",
    "#     # v[1] = data_out_dir\n",
    "\n",
    "#     data = segyio.tools.cube(v[0]) # Every data dimension = (590, 782, 1006)\n",
    "\n",
    "#     # Save ilines into PNG format\n",
    "#     for i in range(n_inlines):\n",
    "#         file_name = os.path.join(v[1], 'Inlines', '{}.png'.format(str(i+1)))\n",
    "#         plt.imsave(file_name, data[i].T)\n",
    "\n",
    "#     # Save ilines into PNG format\n",
    "#     for i in range(n_crosslines):\n",
    "#         file_name = os.path.join(v[1], 'Crosslines', '{}.png'.format(str(i+1)))\n",
    "#         plt.imsave(file_name, data[:, i, :].T)\n",
    "\n",
    "#     # Clean data object in memory\n",
    "#     del data\n",
    "\n",
    "\n",
    "\n",
    "for _, (data_in_dir, data_out_dir) in data_dir_dict.items():\n",
    "    data = segyio.tools.cube(data_in_dir) # Every data dimension = (590, 782, 1006)\n",
    "\n",
    "    # Save ilines into PNG format\n",
    "    for i in range(n_inlines):\n",
    "        file_name = os.path.join(data_out_dir, 'Inlines', '{}.png'.format(str(i+1)))\n",
    "        plt.imsave(file_name, data[i].T)\n",
    "\n",
    "    # Save ilines into PNG format\n",
    "    for i in range(n_crosslines):\n",
    "        file_name = os.path.join(data_out_dir, 'Crosslines', '{}.png'.format(str(i+1)))\n",
    "        plt.imsave(file_name, data[:, i, :].T)\n",
    "\n",
    "    # Clean data object in memory\n",
    "    del data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "\n",
    "#### Extract Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import segyio\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "\n",
    "labels_in_dir = '../dataset/TrainingData_Labels.segy'\n",
    "assert os.path.isfile(labels_in_dir), 'Dataset label tidak ditemukan!'\n",
    "\n",
    "out_dir = os.path.join('output', 'Images')\n",
    "if not os.path.exists(out_dir):\n",
    "    os.makedirs(out_dir)\n",
    "\n",
    "labels_out_dir = os.path.join(out_dir, 'Labels')\n",
    "if not os.path.exists(labels_out_dir):\n",
    "    os.mkdir(labels_out_dir)\n",
    "    os.mkdir(os.path.join(labels_out_dir, 'Inlines'))\n",
    "    os.mkdir(os.path.join(labels_out_dir, 'Crosslines'))\n",
    "\n",
    "\n",
    "\n",
    "data = segyio.tools.cube(labels_in_dir)\n",
    "n_inlines, n_crosslines = (590, 782)\n",
    "\n",
    "for i in range(n_inlines):\n",
    "    file_name = os.path.join(labels_out_dir, 'Inlines', '{}.png'.format(str(i+1)))\n",
    "    plt.imsave(file_name, data[i].T)\n",
    "\n",
    "for i in range(n_crosslines):\n",
    "    file_name = os.path.join(labels_out_dir, 'Crosslines', '{}.png'.format(str(i+1)))\n",
    "    plt.imsave(file_name, data[:, i, :].T)\n",
    "\n",
    "del data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "\n",
    "#### Reading image dataset (inline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from PIL import Image as im\n",
    "import cv2\n",
    "\n",
    "input_image_dir = os.path.join('output', 'Images', 'Amplitude', 'Inlines', '2.png')\n",
    "assert os.path.isfile(input_image_dir), 'Gambar tidak ditemukan!'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PIL:\n",
      "<class 'PIL.PngImagePlugin.PngImageFile'>, (782, 1006)\n",
      "\n",
      "OpenCV:\n",
      "<class 'numpy.ndarray'>, (1006, 782, 3)\n",
      "\n",
      "(782, 1006)\n"
     ]
    }
   ],
   "source": [
    "image_pil = im.open(input_image_dir)\n",
    "image_cv = cv2.imread(input_image_dir)\n",
    "\n",
    "print(f'PIL:\\n{type(image_pil)}, {image_pil.size}\\n')\n",
    "print(f'OpenCV:\\n{type(image_cv)}, {image_cv.shape}\\n')\n",
    "\n",
    "image_cv_no_C = image_cv[:, :, 0].T\n",
    "print(image_cv_no_C.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 782, 1006)\n"
     ]
    }
   ],
   "source": [
    "coba = image_cv.T\n",
    "print(coba.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Catatan lainnya"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TensorFlow dan Keras:\n",
    "- Kelebihan: Kemudahan penggunaan dengan Keras, ekosistem besar, dukungan komunitas, deployment mudah.\n",
    "- Kelemahan: Kurva pembelajaran curam, overhead komputasi, debugging kurang intuitif, ukuran dan kompleksitas framework.\n",
    "\n",
    "PyTorch:\n",
    "- Kelebihan: Fleksibilitas, dynamic computation graph, intuitif untuk penelitian, dukungan komunitas yang berkembang cepat.\n",
    "- Kelemahan: Perubahan besar di rilis baru, ekosistem lebih kecil, deployment lebih kompleks.\n",
    "\n",
    "OpenCV (cv2):\n",
    "- Kelebihan: Sangat fleksibel untuk operasi gambar dan video, kuat untuk pra-pemrosesan gambar.\n",
    "- Kelemahan: Tidak spesifik untuk deep learning, integrasi lebih rumit, membutuhkan lebih banyak kode untuk pra-pemrosesan.\n",
    "\n",
    "Pillow (PIL):\n",
    "- Kelebihan: Mudah digunakan untuk operasi dasar pada gambar, integrasi dengan NumPy.\n",
    "- Kelemahan: Fitur terbatas, performa kurang optimal untuk pengolahan gambar skala besar, tidak spesifik untuk deep learning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# transform = transforms.Compose([\n",
    "#     transforms.Resize((256, 256)),\n",
    "#     transforms.ToTensor()\n",
    "# ])\n",
    "\n",
    "# Harus ke dalam class sehingga dalam folder Inlines,\n",
    "# buat folder class0 dan isi dgn gambar, begitu jg untuk class1 dan seterusnya\n",
    "# dataset = datasets.ImageFolder('path/to/directory', transform=transform)\n",
    "images_dir = os.path.join('output', 'Images', 'Amplitude', 'Inlines')\n",
    "dataset = datasets.ImageFolder(images_dir) # Output: torchvision.datasets.folder.ImageFolder\n",
    "dataloader = DataLoader(dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "# Contoh iterasi melalui DataLoader\n",
    "for images, labels in dataloader:\n",
    "    print(images.shape, labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Original 3D array:\n",
      "[[[1 2]\n",
      "  [3 4]]\n",
      "\n",
      " [[5 6]\n",
      "  [7 8]]]\n",
      "\n",
      "Transposed 3D array with specific axes order using np.transpose:\n",
      "[[[1 2]\n",
      "  [5 6]]\n",
      "\n",
      " [[3 4]\n",
      "  [7 8]]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "array_3d = np.array([[[1, 2], [3, 4]], [[5, 6], [7, 8]]])\n",
    "\n",
    "# Mentansposisi dengan urutan sumbu tertentu\n",
    "transposed_array_3d = np.transpose(array_3d, (1, 0, 2))\n",
    "\n",
    "print(\"\\nOriginal 3D array:\")\n",
    "print(array_3d)\n",
    "print(\"\\nTransposed 3D array with specific axes order using np.transpose:\")\n",
    "print(transposed_array_3d)\n",
    "\n",
    "# [\n",
    "#     [\n",
    "#         [1 2] # 000 001\n",
    "#         [3 4] # 010 011\n",
    "#     ]\n",
    "\n",
    "#     [\n",
    "#         [5 6] # 100 101\n",
    "#         [7 8] # 110 111\n",
    "#     ]\n",
    "# ]\n",
    "\n",
    "# ---\n",
    "\n",
    "# [\n",
    "#     [\n",
    "#         [1 2] # 000 001\n",
    "#         [5 6] # 100 101\n",
    "#     ]\n",
    "\n",
    "#     [\n",
    "#         [3 4] # 010 011\n",
    "#         [7 8] # 110 111\n",
    "#     ]\n",
    "# ]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "seismic-env-kernel",
   "language": "python",
   "name": "seismic-env-kernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
